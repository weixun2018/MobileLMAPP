# 本地部署并实现接口访问

+ 安装依赖

  > 匹配 `CUDA` 版本 11.8

  ```bash
  pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --extra-index-url https://download.pytorch.org/whl/cu118
  ```

  ```bash
  pip install llama-cpp-python[server]
  ```

  