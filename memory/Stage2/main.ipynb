{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhfost:8080/"
        },
        "id": "cysPGSjcuk46",
        "outputId": "db42cbd1-ff8b-4abe-a3f7-f97d6ab7e34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.15.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from chromadb import Client, Settings\n",
        "import chromadb\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# 初始化 MiniCPM 模型\n",
        "path = \"openbmb/MiniCPM3-4B\"\n",
        "device = \"cuda\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    path, torch_dtype=torch.bfloat16, device_map=device, trust_remote_code=True\n",
        ")\n",
        "\n",
        "# 初始化向量模型\n",
        "embed_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "embed_model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    embed_model = embed_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NYbICtg4uosT"
      },
      "outputs": [],
      "source": [
        "# 在当前工作目录下创建chroma_db目录\n",
        "chroma_db_path = os.path.join(os.getcwd(), \"chroma_db\")\n",
        "if not os.path.exists(chroma_db_path):\n",
        "    os.makedirs(chroma_db_path)\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
        "collection = chroma_client.get_or_create_collection(name=\"chat_history\")\n",
        "\n",
        "# 初始化 SQLite 数据库\n",
        "conn = sqlite3.connect(\"chat_history.db\")\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\n",
        "    \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS chat_history (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    user_input TEXT,\n",
        "    ai_response TEXT,\n",
        "    timestamp DATETIME\n",
        ")\n",
        "\"\"\"\n",
        ")\n",
        "conn.commit()\n",
        "\n",
        "def get_embedding(text: str) -> list:\n",
        "    \"\"\"获取文本的向量表示\"\"\"\n",
        "    inputs = embed_tokenizer(\n",
        "        text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
        "    )\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = embed_model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "    return embeddings[0].tolist()\n",
        "\n",
        "def add_chat_history(user_input: str, ai_response: str):\n",
        "    \"\"\"存储对话历史到SQLite\"\"\"\n",
        "    try:\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO chat_history (\n",
        "            user_input,\n",
        "            ai_response,\n",
        "            timestamp\n",
        "        ) VALUES (?, ?, ?)\n",
        "        \"\"\", (\n",
        "            user_input,\n",
        "            ai_response,\n",
        "            datetime.now()\n",
        "        ))\n",
        "        conn.commit()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"存储聊天历史时出错: {str(e)}\")\n",
        "        conn.rollback()\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RgCOgONzuudy"
      },
      "outputs": [],
      "source": [
        "def split_counseling_text(text: str, chunk_size: int = 150, overlap: int = 50) :\n",
        "    \"\"\"专门针对心理咨询内容的文本分割\n",
        "\n",
        "    Args:\n",
        "        text: 要分割的文本\n",
        "        chunk_size: 每个块的目标大小\n",
        "        overlap: 重叠部分的大小，用于保持上下文连贯性\n",
        "    \"\"\"\n",
        "    def is_sentence_boundary(text: str, pos: int) -> bool:\n",
        "        \"\"\"判断是否是自然的句子边界\"\"\"\n",
        "        if pos >= len(text):\n",
        "            return True\n",
        "\n",
        "        # 标点符号表示句子结束\n",
        "        end_marks = ['。', '！', '？', '…', '.', '!', '?']\n",
        "        if any(text[pos] == mark for mark in end_marks):\n",
        "            return True\n",
        "\n",
        "        # 表示说话或情绪的标点\n",
        "        speech_marks = ['：', ':', '\"', '\"', ''', ''']\n",
        "        if any(text[pos] == mark for mark in speech_marks):\n",
        "            return False\n",
        "\n",
        "        return False\n",
        "\n",
        "    def find_best_split_position(text: str, target_pos: int) -> int:\n",
        "        \"\"\"寻找最佳分割点\"\"\"\n",
        "        # 在目标位置前后寻找最近的句子边界\n",
        "        left = right = target_pos\n",
        "\n",
        "        # 向左搜索\n",
        "        while left > 0 and not is_sentence_boundary(text, left):\n",
        "            left -= 1\n",
        "\n",
        "        # 向右搜索\n",
        "        while right < len(text) and not is_sentence_boundary(text, right):\n",
        "            right += 1\n",
        "\n",
        "        # 选择距离目标位置最近的边界\n",
        "        if target_pos - left <= right - target_pos and left > 0:\n",
        "            return left + 1\n",
        "        return right + 1\n",
        "\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    text_length = len(text)\n",
        "\n",
        "    while start < text_length:\n",
        "        # 确定当前块的结束位置\n",
        "        end = min(start + chunk_size, text_length)\n",
        "\n",
        "        if end < text_length:\n",
        "            # 寻找最佳分割点\n",
        "            end = find_best_split_position(text, end)\n",
        "\n",
        "        # 提取当前块\n",
        "        current_chunk = text[start:end].strip()\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        # 计算下一个块的起始位置（考虑重叠）\n",
        "        start = max(start + chunk_size - overlap, end - overlap)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KnJDKOIRcaTZ"
      },
      "outputs": [],
      "source": [
        "def add_to_knowledge_base(content: str, chunk_size: int = 150):\n",
        "    \"\"\"向知识库添加心理咨询内容\"\"\"\n",
        "    try:\n",
        "        # 使用专门的分割方法\n",
        "        chunks = split_counseling_text(content, chunk_size=chunk_size)\n",
        "\n",
        "        print(f\"\\n文本被分割成 {len(chunks)} 个块:\")\n",
        "        for i, chunk in enumerate(chunks, 1):\n",
        "            print(f\"\\n块 {i}:\")\n",
        "            print(chunk)\n",
        "\n",
        "            try:\n",
        "                embedding = get_embedding(chunk)\n",
        "                collection.add(\n",
        "                    documents=[chunk],\n",
        "                    embeddings=[embedding],\n",
        "                    ids=[str(len(collection.get()[\"ids\"]) + 1)]\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"处理块 {i} 时出错: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        return {\n",
        "            'status': 'success',\n",
        "            'chunks_processed': len(chunks)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"添加到知识库时出错: {str(e)}\")\n",
        "        return {\n",
        "            'status': 'error',\n",
        "            'error': str(e)\n",
        "        }\n",
        "\n",
        "def check_knowledge_base():\n",
        "    \"\"\"检查知识库内容\"\"\"\n",
        "    print(\"\\n=== ChromaDB 知识库内容 ===\")\n",
        "    try:\n",
        "        results = collection.get()\n",
        "        print(f\"ChromaDB 中共有 {len(results['documents'])} 条记录\")\n",
        "        for i, (doc, id) in enumerate(zip(results['documents'], results['ids']), 1):\n",
        "            print(f\"\\n文档 {i} (ID: {id}):\")\n",
        "            print(doc)\n",
        "    except Exception as e:\n",
        "        print(f\"获取 ChromaDB 内容时出错: {str(e)}\")\n",
        "\n",
        "    print(\"\\n=== SQLite 对话历史 ===\")\n",
        "    try:\n",
        "        cursor.execute(\"\"\"\n",
        "            SELECT id, timestamp, user_input, ai_response\n",
        "            FROM chat_history\n",
        "            ORDER BY timestamp DESC\n",
        "        \"\"\")\n",
        "        rows = cursor.fetchall()\n",
        "        print(f\"SQLite 中共有 {len(rows)} 条对话记录\")\n",
        "        for row in rows:\n",
        "            print(f\"\\n对话ID: {row[0]}\")\n",
        "            print(f\"时间: {row[1]}\")\n",
        "            print(f\"用户: {row[2]}\")\n",
        "            print(f\"AI: {row[3]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"获取 SQLite 内容时出错: {str(e)}\")\n",
        "\n",
        "def search_similar_from_chromadb(query: str, similarity_threshold: float = 0.7, limit: int = 10) -> list:\n",
        "    \"\"\"从ChromaDB搜索语义相似的对话记录，并显示相似度\n",
        "\n",
        "    Args:\n",
        "        query: 查询文本\n",
        "        similarity_threshold: 相似度阈值\n",
        "        limit: 返回结果数量限制\n",
        "    \"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "    results = collection.query(query_embeddings=[query_embedding], n_results=limit)\n",
        "\n",
        "    semantic_matches = []\n",
        "    print(\"\\n=== 相似度排序结果 ===\")\n",
        "    if results[\"documents\"]:\n",
        "        distances = results.get(\"distances\", [[]])[0]\n",
        "        for i, (doc, distance) in enumerate(zip(results[\"documents\"][0], distances), 1):\n",
        "            # 使用余弦相似度计算\n",
        "            doc_embedding = get_embedding(doc)\n",
        "            similarity = np.dot(query_embedding, doc_embedding) / (\n",
        "                np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)\n",
        "            )\n",
        "\n",
        "            print(f\"\\n文档 {i}:\")\n",
        "            print(f\"相似度: {similarity:.4f}\")\n",
        "            print(f\"内容: {doc}\")\n",
        "\n",
        "            if similarity >= similarity_threshold:\n",
        "                semantic_matches.append({\n",
        "                    'content': doc,\n",
        "                    'similarity': similarity\n",
        "                })\n",
        "\n",
        "    # 按相似度排序\n",
        "    semantic_matches.sort(key=lambda x: x['similarity'], reverse=True)\n",
        "    return semantic_matches\n",
        "\n",
        "def get_recent_history_from_sqlite(limit: int = 5) -> list:\n",
        "    \"\"\"从SQLite获取最近的对话历史\n",
        "\n",
        "    Args:\n",
        "        limit: 返回的历史记录数量\n",
        "\n",
        "    Returns:\n",
        "        list: 最近的对话记录列表\n",
        "    \"\"\"\n",
        "    cursor.execute(\n",
        "        \"\"\"\n",
        "    SELECT user_input, ai_response FROM chat_history\n",
        "    ORDER BY timestamp DESC LIMIT ?\n",
        "    \"\"\", (limit,)\n",
        "    )\n",
        "    return [f\"问：{row[0]}\\n答：{row[1]}\" for row in cursor.fetchall()]\n",
        "\n",
        "def search_relevant(query: str, similarity_threshold: float = 0.7, limit: int = 10) -> tuple:\n",
        "    \"\"\"搜索相似的历史对话，同时从ChromaDB和SQLite获取结果\"\"\"\n",
        "    semantic_matches = search_similar_from_chromadb(query, similarity_threshold, limit)\n",
        "    recent_history = get_recent_history_from_sqlite()\n",
        "\n",
        "    print(\"\\n=== 最终筛选结果 ===\")\n",
        "    print(f\"\\n高于阈值({similarity_threshold})的匹配结果:\")\n",
        "    for i, match in enumerate(semantic_matches, 1):\n",
        "        print(f\"\\n匹配 {i}:\")\n",
        "        print(f\"相似度: {match['similarity']:.4f}\")\n",
        "        print(f\"内容: {match['content']}\")\n",
        "\n",
        "    print(\"\\n最近对话历史:\")\n",
        "    for i, history in enumerate(recent_history, 1):\n",
        "        print(f\"\\n历史记录 {i}:\")\n",
        "        print(history)\n",
        "\n",
        "    return semantic_matches, recent_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t6DB36Pgu_th",
        "outputId": "d6de5b99-128e-408a-cb8b-d57252f7401b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "开始对话（输入'exit'结束）...\n",
            "\n",
            "用户: 我是小明\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 相似度排序结果 ===\n",
            "\n",
            "=== 最终筛选结果 ===\n",
            "\n",
            "高于阈值(0.7)的匹配结果:\n",
            "\n",
            "最近对话历史:\n",
            "\n",
            "文本被分割成 1 个块:\n",
            "\n",
            "块 1:\n",
            "你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "AI: 你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "用户: 我今年18岁\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 10 is greater than number of elements in index 1, updating n_results = 1\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 相似度排序结果 ===\n",
            "\n",
            "文档 1:\n",
            "相似度: 0.5554\n",
            "内容: 你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "=== 最终筛选结果 ===\n",
            "\n",
            "高于阈值(0.7)的匹配结果:\n",
            "\n",
            "最近对话历史:\n",
            "\n",
            "历史记录 1:\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "最近对话记录：\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文本被分割成 4 个块:\n",
            "\n",
            "块 1:\n",
            "了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。\n",
            "\n",
            "块 2:\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。\n",
            "\n",
            "块 3:\n",
            "黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "块 4:\n",
            "康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "AI: 了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "用户: 我叫什么名字\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 10 is greater than number of elements in index 5, updating n_results = 5\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 相似度排序结果 ===\n",
            "\n",
            "文档 1:\n",
            "相似度: 0.5996\n",
            "内容: 你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文档 2:\n",
            "相似度: 0.5317\n",
            "内容: 康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "文档 3:\n",
            "相似度: 0.4833\n",
            "内容: 在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。\n",
            "\n",
            "文档 4:\n",
            "相似度: 0.4641\n",
            "内容: 黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "文档 5:\n",
            "相似度: 0.4507\n",
            "内容: 了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。\n",
            "\n",
            "=== 最终筛选结果 ===\n",
            "\n",
            "高于阈值(0.7)的匹配结果:\n",
            "\n",
            "最近对话历史:\n",
            "\n",
            "历史记录 1:\n",
            "问：我今年18岁\n",
            "答：了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "历史记录 2:\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "最近对话记录：\n",
            "问：我今年18岁\n",
            "答：了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文本被分割成 1 个块:\n",
            "\n",
            "块 1:\n",
            "你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "\n",
            "AI: 你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "\n",
            "用户: 我今年多少岁\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 10 is greater than number of elements in index 6, updating n_results = 6\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 相似度排序结果 ===\n",
            "\n",
            "文档 1:\n",
            "相似度: 0.6344\n",
            "内容: 康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "文档 2:\n",
            "相似度: 0.5814\n",
            "内容: 你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文档 3:\n",
            "相似度: 0.5196\n",
            "内容: 你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "\n",
            "文档 4:\n",
            "相似度: 0.5437\n",
            "内容: 了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。\n",
            "\n",
            "文档 5:\n",
            "相似度: 0.5320\n",
            "内容: 在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。\n",
            "\n",
            "文档 6:\n",
            "相似度: 0.5035\n",
            "内容: 黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "=== 最终筛选结果 ===\n",
            "\n",
            "高于阈值(0.7)的匹配结果:\n",
            "\n",
            "最近对话历史:\n",
            "\n",
            "历史记录 1:\n",
            "问：我叫什么名字\n",
            "答：你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "\n",
            "历史记录 2:\n",
            "问：我今年18岁\n",
            "答：了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "历史记录 3:\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "最近对话记录：\n",
            "问：我叫什么名字\n",
            "答：你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "问：我今年18岁\n",
            "答：了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文本被分割成 1 个块:\n",
            "\n",
            "块 1:\n",
            "你好，小明！从你的对话记录来看，你今年18岁。如果你还有其他问题或需要帮助，随时告诉我，我会很乐意帮助你。\n",
            "\n",
            "AI: 你好，小明！从你的对话记录来看，你今年18岁。如果你还有其他问题或需要帮助，随时告诉我，我会很乐意帮助你。\n",
            "\n",
            "用户: 你知道哪些关于我的信息\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 10 is greater than number of elements in index 7, updating n_results = 7\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 相似度排序结果 ===\n",
            "\n",
            "文档 1:\n",
            "相似度: 0.6990\n",
            "内容: 你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文档 2:\n",
            "相似度: 0.6250\n",
            "内容: 你好，小明！从你的对话记录来看，你今年18岁。如果你还有其他问题或需要帮助，随时告诉我，我会很乐意帮助你。\n",
            "\n",
            "文档 3:\n",
            "相似度: 0.5341\n",
            "内容: 康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "文档 4:\n",
            "相似度: 0.4688\n",
            "内容: 黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "文档 5:\n",
            "相似度: 0.4657\n",
            "内容: 你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "\n",
            "文档 6:\n",
            "相似度: 0.4576\n",
            "内容: 在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。\n",
            "\n",
            "文档 7:\n",
            "相似度: 0.4177\n",
            "内容: 了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。\n",
            "\n",
            "=== 最终筛选结果 ===\n",
            "\n",
            "高于阈值(0.7)的匹配结果:\n",
            "\n",
            "最近对话历史:\n",
            "\n",
            "历史记录 1:\n",
            "问：我今年多少岁\n",
            "答：你好，小明！从你的对话记录来看，你今年18岁。如果你还有其他问题或需要帮助，随时告诉我，我会很乐意帮助你。\n",
            "\n",
            "历史记录 2:\n",
            "问：我叫什么名字\n",
            "答：你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "\n",
            "历史记录 3:\n",
            "问：我今年18岁\n",
            "答：了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "\n",
            "历史记录 4:\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "最近对话记录：\n",
            "问：我今年多少岁\n",
            "答：你好，小明！从你的对话记录来看，你今年18岁。如果你还有其他问题或需要帮助，随时告诉我，我会很乐意帮助你。\n",
            "问：我叫什么名字\n",
            "答：你好，你只是匿名发了一个“我是小明”，并没有提供你的全名。如果你想分享你的全名，我可以帮你设定一个与你全名相关的个性签名；如果你不想分享，我也可以帮你设定一个匿名个性签名。请告诉我你的选择。\n",
            "问：我今年18岁\n",
            "答：了解到小明你今年18岁，正值青春年华，这是一个充满活力与可能的年纪。18岁意味着你已经成年，可以为自己做出更多的选择和决定。这是一个重要的成长阶段，你可以开始规划自己的未来，追求梦想，同时也要学会承担责任。\n",
            "\n",
            "在这个年纪，你可能在学校接受教育，为将来的职业生涯做准备，或者你可能已经开始工作，积累社会经验。无论你选择哪条路，都要记得保持学习的心态，不断探索自我，挑战自我。\n",
            "\n",
            "同时，18岁也是建立人际关系的黄金时期，你可以结交志同道合的朋友，拓展社交圈，这将对你的个人成长产生积极影响。不要害怕尝试新事物，勇敢地追求自己的兴趣和激情，这将让你的生活更加丰富多彩。\n",
            "\n",
            "最后，记得保持健康的生活方式，关注身心健康，这是你成长的基石。祝你在18岁这一年，以及未来的日子里，能够勇敢追梦，活出精彩！\n",
            "问：我是小明\n",
            "答：你好，小明，很高兴认识你！如果是为了解决某个问题或寻求建议，请随时告诉我你需要的信息，我会尽我所能提供帮助。如果有任何疑问，也需要随时向我提问。\n",
            "\n",
            "文本被分割成 1 个块:\n",
            "\n",
            "块 1:\n",
            "根据我们的对话记录，我知道你的名字是小明，你今年18岁。除此之外，我并不知道你更多的个人信息。如果你希望我了解更多信息，或者你有任何问题需要帮助，随时告诉我，我会尽力提供支持。\n",
            "\n",
            "AI: 根据我们的对话记录，我知道你的名字是小明，你今年18岁。除此之外，我并不知道你更多的个人信息。如果你希望我了解更多信息，或者你有任何问题需要帮助，随时告诉我，我会尽力提供支持。\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c3a56fea7c25>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# 开始对话\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mchat_with_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-c3a56fea7c25>\u001b[0m in \u001b[0;36mchat_with_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n用户: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bye\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "def chat_with_memory():\n",
        "    \"\"\"对话主循环\"\"\"\n",
        "    print(\"开始对话（输入'exit'结束）...\")\n",
        "    history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\n用户: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            # 搜索相关历史记忆和最近对话\n",
        "            semantic_matches, recent_history = search_relevant(user_input)\n",
        "\n",
        "            # 构建提示\n",
        "            prompt = user_input\n",
        "            context_parts = []\n",
        "\n",
        "            if semantic_matches:\n",
        "                context_parts.append(\"相关历史对话：\\n\" + \"\\n\".join(semantic_matches))\n",
        "            if recent_history:\n",
        "                context_parts.append(\"最近对话记录：\\n\" + \"\\n\".join(recent_history))\n",
        "\n",
        "            if context_parts:\n",
        "                context = \"\\n\\n\".join(context_parts)\n",
        "                prompt = f\"{context}\\n\\n当前问题：{user_input}\"\n",
        "                print(\"\\n\" + context)\n",
        "\n",
        "            # 生成回答\n",
        "            response, history = model.chat(tokenizer, prompt, history=history)\n",
        "\n",
        "            # 存储完整对话记录以及相关历史记忆\n",
        "            add_chat_history(user_input, response)\n",
        "            add_to_knowledge_base(response)\n",
        "\n",
        "            print(\"\\nAI:\", response)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n发生错误: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 开始对话\n",
        "    chat_with_memory()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0aecc5c25f7a43f2ab33a88225fe8ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f09f73a5cb485faf6a03c12c4bb1e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad23d53bc2a4e78b41c7202d76b30f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8775f842424dcaa1601f045e1acde5",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b483f5d46c485a9e0f360d13f14b76",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7242e55640cb45eca9b010f3018daa1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48f09f73a5cb485faf6a03c12c4bb1e5",
            "placeholder": "​",
            "style": "IPY_MODEL_c72145a18fde451fa882a40e85501cbb",
            "value": " 2/2 [00:05&lt;00:00,  2.48s/it]"
          }
        },
        "7a8775f842424dcaa1601f045e1acde5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80490de5560b43449c57c73840c3b0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974702b114f14268b83d914680b13e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80490de5560b43449c57c73840c3b0ef",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a99f631d4151417e89db66a3dbcb1985",
            "value": 2
          }
        },
        "a99f631d4151417e89db66a3dbcb1985": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8b483f5d46c485a9e0f360d13f14b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfb396eda7c748b1bd47d003924922e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ad23d53bc2a4e78b41c7202d76b30f5",
              "IPY_MODEL_974702b114f14268b83d914680b13e8c",
              "IPY_MODEL_7242e55640cb45eca9b010f3018daa1e"
            ],
            "layout": "IPY_MODEL_0aecc5c25f7a43f2ab33a88225fe8ab8"
          }
        },
        "c72145a18fde451fa882a40e85501cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
